{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPwxOpy9ChZ/SyQO3IOzEiV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/esterhsieh/MystanCodeProJects/blob/main/Amazon_Reviews_for_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-y1XbJPB27U5",
        "outputId": "b2ad5bd1-7e5a-4e9c-e721-033eeb3dae96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Colab Notebooks/practice_20230418\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "FOLDERNAME = 'Colab\\ Notebooks/practice_20230418'\n",
        "%cd drive/MyDrive/$FOLDERNAME/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import pandas as pd\n",
        "import os\n",
        "import time"
      ],
      "metadata": {
        "id": "_qXWhOXY4vdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Seed for same output\n",
        "torch.manual_seed(42)\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "C_AF8PWb4va9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyq-Lnby4vYK",
        "outputId": "15f62c5d-4911-4e0f-84cd-32afb2d8ce5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_reviews_and_labels(filepath):\n",
        "  with open(filepath, 'r') as f:\n",
        "    reviews = []\n",
        "    labels = []\n",
        "    for line in f:\n",
        "      reviews.append(line[10:].strip())\n",
        "      labels.append(int(line[9])-1)\n",
        "    reviews = reviews[:int(len(reviews)*0.5)]\n",
        "    labels = labels[:int(len(labels)*0.5)]\n",
        "    return reviews, labels\n",
        "\n",
        "train_reviews, train_labels = get_reviews_and_labels('train.ft.txt')\n",
        "test_reviews, test_labels = get_reviews_and_labels('test.ft.txt')"
      ],
      "metadata": {
        "id": "lNwiWiuj4vVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patterns = ['<br />', '--', '.', ',', '!', '?', ')', '(', ';', ':', '*', '~', '_', \"'\", '\"']\n",
        "replacements = [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '', '']"
      ],
      "metadata": {
        "id": "AF6SEXfM4vSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(reviews, patterns, replacements):\n",
        "  for i in range(len(reviews)):\n",
        "    review = reviews[i].lower()\n",
        "    for pattern, replacement in zip(patterns, replacements):\n",
        "      review = review.replace(pattern, replacement)\n",
        "    reviews[i] = review\n",
        "  return reviews"
      ],
      "metadata": {
        "id": "3nNxgSFf4vQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_reviews = preprocessing(train_reviews, patterns, replacements)\n",
        "test_datas = preprocessing(test_reviews, patterns, replacements)"
      ],
      "metadata": {
        "id": "c0JP-jmN4vNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import model_selection\n",
        "train_reviews, val_reviews, train_labels, val_labels = model_selection.train_test_split(train_reviews, train_labels, test_size = 0.40, random_state=42)"
      ],
      "metadata": {
        "id": "lN5AHqlSEuSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_train = len(train_reviews)\n",
        "num_val = len(val_reviews)\n",
        "num_test = len(test_datas)\n",
        "longest_num_tokens = 250"
      ],
      "metadata": {
        "id": "xBHt_oLj4vKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def indexing_tokens():\n",
        "  indices = {'<start>':0, '<end>':1, '<pad>':2, '<unk>':3}\n",
        "  counter = 4\n",
        "  for i in range(num_train):\n",
        "    tokens = train_reviews[i].split()\n",
        "    for token in tokens:\n",
        "      if token not in indices:\n",
        "        indices[token] = counter\n",
        "        counter += 1\n",
        "  return indices"
      ],
      "metadata": {
        "id": "-azwT_rU4vHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data(indices, longest_num_tokens, mode='train'):\n",
        "  data = []\n",
        "  Y = []\n",
        "  if mode == 'train':\n",
        "    for i in range(num_train):\n",
        "      train_data = []\n",
        "      label, tokens = train_labels[i], train_reviews[i].split()\n",
        "      for token in tokens:\n",
        "        train_data.append(indices[token])\n",
        "        if len(train_data) == longest_num_tokens:\n",
        "          break\n",
        "      while len(train_data) < longest_num_tokens:\n",
        "        train_data.append(indices['<pad>'])\n",
        "      train_data.insert(indices['<start>'], 0)\n",
        "      train_data.append(indices['<end>'])\n",
        "      data.append(train_data)\n",
        "      Y.append(label)\n",
        "  elif mode == 'val':\n",
        "    for i in range(num_val):\n",
        "      val_data = []\n",
        "      label, tokens = val_labels[i], val_reviews[i].split()\n",
        "      for token in tokens:\n",
        "        if token in indices:\n",
        "          val_data.append(indices[token])\n",
        "        else:\n",
        "          val_data.append(indices['<unk>'])\n",
        "        if len(val_data) == longest_num_tokens:\n",
        "          break\n",
        "      while len(val_data) < longest_num_tokens:\n",
        "        val_data.append(indices['<pad>'])\n",
        "      val_data.insert(indices['<start>'], 0)\n",
        "      val_data.append(indices['<end>'])\n",
        "      data.append(val_data)\n",
        "      Y.append(label)\n",
        "  else:\n",
        "    for i in range(num_test):\n",
        "      test_data = []\n",
        "      label, tokens = test_labels[i], test_datas[i].split()\n",
        "      for token in tokens:\n",
        "        if token in indices:\n",
        "          test_data.append(indices[token])\n",
        "        else:\n",
        "          test_data.append(indices['<unk>'])\n",
        "        if len(test_data) == longest_num_tokens:\n",
        "          break\n",
        "      while len(test_data) < longest_num_tokens:\n",
        "        test_data.append(indices['<pad>'])\n",
        "      test_data.insert(indices['<start>'], 0)\n",
        "      test_data.append(indices['<end>'])\n",
        "      data.append(test_data)\n",
        "      Y.append(label)\n",
        "  return data, Y"
      ],
      "metadata": {
        "id": "MxwY80ejGRTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading Training Data & Val Data\n",
        "indices = indexing_tokens()\n",
        "train_data, train_labels = get_data(indices, longest_num_tokens)\n",
        "val_data, val_labels = get_data(indices, longest_num_tokens, mode='val')"
      ],
      "metadata": {
        "id": "7lC_nCEVGRQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of training:', len(train_data))\n",
        "print('Number of validation:', len(val_data))\n",
        "print('Length of corpus:', len(indices))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7M-go4_GRNk",
        "outputId": "b24b4555-a076-4a3d-fb90-8319f13b4ba8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training: 1080000\n",
            "Number of validation: 720000\n",
            "Length of corpus: 667057\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create tensors of train & val\n",
        "train_tensor = torch.tensor(train_data)\n",
        "train_labels_tensor = torch.tensor(train_labels)\n",
        "val_tensor = torch.tensor(val_data)\n",
        "val_labels_tensor = torch.tensor(val_labels)"
      ],
      "metadata": {
        "id": "ftO6Oe0PGRLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Train Tensor:', train_tensor.shape)\n",
        "print('Val Tensor:', val_tensor.shape)\n",
        "print('Train Label Tensor:', train_labels_tensor.shape)\n",
        "print('Val Label Tensor:', val_labels_tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a05SKTeRGRIh",
        "outputId": "8e839984-bcfb-4c53-db84-31dbb47f37b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Tensor: torch.Size([1080000, 252])\n",
            "Val Tensor: torch.Size([720000, 252])\n",
            "Train Label Tensor: torch.Size([1080000])\n",
            "Val Label Tensor: torch.Size([720000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_embeddings = len(indices)\n",
        "embedding_dim = 300\n",
        "hidden_dim = 256\n",
        "sequence_len = 252\n",
        "output_dim = 2\n",
        "print_every = 5000\n",
        "batch_size = 64"
      ],
      "metadata": {
        "id": "o8fP11IzGRFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(nn.Module):\n",
        "  def __init__(self, num_embeddings, embedding_dim, hidden_dim, output_dim):\n",
        "    super().__init__()\n",
        "    self.embedding_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "    self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "  def forward(self, x):\n",
        "    # x.shape = N * 252\n",
        "    embedding_data = self.embedding_layer(x)\n",
        "    # x.shape = M * 252 * 100\n",
        "    output, (h_n, c_n) = self.lstm(embedding_data)\n",
        "    out = output[:, -1, :]\n",
        "    return self.fc(out)"
      ],
      "metadata": {
        "id": "dEnRTpIBGRDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel(num_embeddings, embedding_dim, hidden_dim, output_dim)\n",
        "model = model.cuda()"
      ],
      "metadata": {
        "id": "NZEIeLVaGRAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mini_trains = DataLoader(train_tensor, batch_size=batch_size)\n",
        "mini_train_labels = DataLoader(train_labels_tensor, batch_size=batch_size)\n",
        "\n",
        "mini_vals = DataLoader(val_tensor, batch_size=batch_size)\n",
        "mini_val_labels = DataLoader(val_labels_tensor, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "OKf3L-GuGQ86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Procedure\n",
        "def train(num_epoch, model, mini_trains, mini_train_labels, mini_vals, mini_val_labels, device, loss_function, optimizer):\n",
        "  for epoch in range(num_epoch):\n",
        "    for counter, (x, y) in enumerate(zip(mini_trains, mini_train_labels)):\n",
        "      model.train()\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "      scores = model(x)\n",
        "      loss = loss_function(scores, y)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      if counter % print_every == 0:\n",
        "        evaluate_predictor(model, epoch, mini_vals, mini_val_labels, device)"
      ],
      "metadata": {
        "id": "smm1EcVINKhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_predictor(model, epoch, mini_vals, mini_val_labels, device):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    total_acc = 0\n",
        "    for x, y in zip(mini_vals, mini_val_labels):\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "      scores = model(x)\n",
        "      predictions = scores.max(1)[1]\n",
        "      acc = predictions.eq(y).sum().item()\n",
        "      total_acc += acc\n",
        "    print(f'Epoch[{epoch+1}] Acc: {total_acc/len(val_data)}')"
      ],
      "metadata": {
        "id": "sb-ZN16fNKes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch.optim as optim\n",
        "\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
      ],
      "metadata": {
        "id": "nZz0XbUBNKcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start training \n",
        "train(4, model, mini_trains, mini_train_labels, mini_vals, mini_val_labels, device, loss_function, optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPEAwHy0R_Y9",
        "outputId": "c12f7739-6db4-40eb-dd6b-73d895f1c0b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch[1] Acc: 0.5023277777777778\n",
            "Epoch[1] Acc: 0.5023277777777778\n",
            "Epoch[1] Acc: 0.5023277777777778\n",
            "Epoch[1] Acc: 0.5023277777777778\n",
            "Epoch[2] Acc: 0.49767222222222224\n",
            "Epoch[2] Acc: 0.5786111111111111\n",
            "Epoch[2] Acc: 0.8573194444444444\n",
            "Epoch[2] Acc: 0.9012222222222223\n",
            "Epoch[3] Acc: 0.9042736111111112\n",
            "Epoch[3] Acc: 0.9209083333333333\n",
            "Epoch[3] Acc: 0.9268430555555556\n",
            "Epoch[3] Acc: 0.9302027777777778\n",
            "Epoch[4] Acc: 0.9318069444444445\n",
            "Epoch[4] Acc: 0.9351486111111111\n",
            "Epoch[4] Acc: 0.9342833333333334\n",
            "Epoch[4] Acc: 0.9353930555555555\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading Testing Data\n",
        "test_data, test_labels = get_data(indices, longest_num_tokens, mode='test')\n",
        "# Create tensors of test\n",
        "test_tensor = torch.tensor(test_data)\n",
        "test_labels_tensor = torch.tensor(test_labels)"
      ],
      "metadata": {
        "id": "-D5dDg_na3Ei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Test Tensor:', test_tensor.shape)\n",
        "print('Test Label Tensor:', test_labels_tensor.shape)"
      ],
      "metadata": {
        "id": "bkBkcCRXcQOI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ec934df-85d1-4947-f141-fe54219a440e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Tensor: torch.Size([200000, 252])\n",
            "Test Label Tensor: torch.Size([200000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mini_tests = DataLoader(test_tensor, batch_size=1, shuffle=False)\n",
        "mini_test_labels = DataLoader(test_labels_tensor, batch_size=1)"
      ],
      "metadata": {
        "id": "OfZ4bq40cbgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, mini_tests, mini_test_labels, device):\n",
        "  model.eval()\n",
        "  start = time.time()\n",
        "  with torch.no_grad():\n",
        "    total_acc = 0\n",
        "    predictions = []\n",
        "    for x, y in zip(mini_tests, mini_test_labels):\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "      scores = model(x)\n",
        "      prediction = scores.max(1)[1]\n",
        "      predictions.append(prediction.item())\n",
        "      acc = prediction.eq(y).sum().item()\n",
        "      total_acc += acc\n",
        "    end = time.time()\n",
        "    elapsed = end - start\n",
        "    print(f'Testing acc: {total_acc/len(test_data)}, tiem_spent: {round(elapsed, 2)} sec')\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "jvBjCO0Jcl9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = predict(model, mini_tests, mini_test_labels, device)\n",
        "# submission = pd.DataFrame(zip(test_reviews, predictions), columns=['text','label'])\n",
        "# submission.to_csv('submission_lstm.csv', index=False)"
      ],
      "metadata": {
        "id": "p0QXRnuJeXKd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8dddbd4-c43a-446d-a03c-5f6140ff6a98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing acc: 0.93851, tiem_spent: 644.48 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def out_file(predictions, test_reviews, test_labels, out_filename):\n",
        "\n",
        "    print('\\n===============================================')\n",
        "    print(f'Writing predictions to --> {out_filename}')\n",
        "    with open(out_filename, 'w') as out:\n",
        "        for prediction, test_review in zip(predictions, test_reviews):\n",
        "          out.write('__label__' + str(prediction+1) + '\\t' + str(test_review) + '\\n')\n",
        "    print('===============================================')\n",
        "\n",
        "out_file(predictions, test_reviews, test_labels, 'Amazon_Reviews_for_Sentiment_Analysis_lstm_epoch4.txt')"
      ],
      "metadata": {
        "id": "8luY_yBsR_WU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ffac4ea-5589-4d0c-be5a-f4e312ab10fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===============================================\n",
            "Writing predictions to --> Amazon_Reviews_for_Sentiment_Analysis_lstm_epoch4.txt\n",
            "===============================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qYGesSbbR_Ts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qUCnzitlR_Rs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}