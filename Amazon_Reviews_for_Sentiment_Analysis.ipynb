{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-y1XbJPB27U5",
        "outputId": "bbe1e627-42c5-41dc-eac4-0ac814bad2a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Colab Notebooks/Amazon Reviews for Sentiment Analysis\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "FOLDERNAME = 'Colab\\ Notebooks/Amazon Reviews for Sentiment Analysis'\n",
        "%cd drive/MyDrive/$FOLDERNAME/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qXWhOXY4vdt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import pandas as pd\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_AF8PWb4va9"
      },
      "outputs": [],
      "source": [
        "# Seed for same output\n",
        "torch.manual_seed(42)\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyq-Lnby4vYK",
        "outputId": "52f1ec3f-8bea-4135-ed30-007c25bc1109"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNwiWiuj4vVR"
      },
      "outputs": [],
      "source": [
        "def get_reviews_and_labels(filepath):\n",
        "  with open(filepath, 'r') as f:\n",
        "    reviews = []\n",
        "    labels = []\n",
        "    for line in f:\n",
        "      reviews.append(line[10:].strip())\n",
        "      labels.append(int(line[9])-1)\n",
        "    reviews = reviews[:int(len(reviews)*0.506)]\n",
        "    labels = labels[:int(len(labels)*0.506)]\n",
        "    return reviews, labels\n",
        "\n",
        "train_reviews, train_labels = get_reviews_and_labels('train.ft.txt')\n",
        "test_reviews, test_labels = get_reviews_and_labels('test.ft.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AF6SEXfM4vSz"
      },
      "outputs": [],
      "source": [
        "patterns = ['<br />', '--', '.', ',', '!', '?', ')', '(', ';', ':', '*', '~', '_', \"'\", '\"']\n",
        "replacements = [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '', '']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nNxgSFf4vQA"
      },
      "outputs": [],
      "source": [
        "def preprocessing(reviews, patterns, replacements):\n",
        "  for i in range(len(reviews)):\n",
        "    review = reviews[i].lower()\n",
        "    for pattern, replacement in zip(patterns, replacements):\n",
        "      review = review.replace(pattern, replacement)\n",
        "    reviews[i] = review\n",
        "  return reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0JP-jmN4vNH"
      },
      "outputs": [],
      "source": [
        "train_reviews = preprocessing(train_reviews, patterns, replacements)\n",
        "test_datas = preprocessing(test_reviews, patterns, replacements)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lN5AHqlSEuSo"
      },
      "outputs": [],
      "source": [
        "from sklearn import model_selection\n",
        "train_reviews, val_reviews, train_labels, val_labels = model_selection.train_test_split(train_reviews, train_labels, test_size = 0.4, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBHt_oLj4vKd"
      },
      "outputs": [],
      "source": [
        "num_train = len(train_reviews)\n",
        "num_val = len(val_reviews)\n",
        "num_test = len(test_datas)\n",
        "longest_num_tokens = 250"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-azwT_rU4vHP"
      },
      "outputs": [],
      "source": [
        "def indexing_tokens():\n",
        "  indices = {'<start>':0, '<end>':1, '<pad>':2, '<unk>':3}\n",
        "  counter = 4\n",
        "  for i in range(num_train):\n",
        "    tokens = train_reviews[i].split()\n",
        "    for token in tokens:\n",
        "      if token not in indices:\n",
        "        indices[token] = counter\n",
        "        counter += 1\n",
        "  return indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxwY80ejGRTB"
      },
      "outputs": [],
      "source": [
        "def get_data(indices, longest_num_tokens, mode='train'):\n",
        "  data = []\n",
        "  Y = []\n",
        "  if mode == 'train':\n",
        "    for i in range(num_train):\n",
        "      train_data = []\n",
        "      label, tokens = train_labels[i], train_reviews[i].split()\n",
        "      for token in tokens:\n",
        "        train_data.append(indices[token])\n",
        "        if len(train_data) == longest_num_tokens:\n",
        "          break\n",
        "      while len(train_data) < longest_num_tokens:\n",
        "        train_data.append(indices['<pad>'])\n",
        "      train_data.insert(indices['<start>'], 0)\n",
        "      train_data.append(indices['<end>'])\n",
        "      data.append(train_data)\n",
        "      Y.append(label)\n",
        "  elif mode == 'val':\n",
        "    for i in range(num_val):\n",
        "      val_data = []\n",
        "      label, tokens = val_labels[i], val_reviews[i].split()\n",
        "      for token in tokens:\n",
        "        if token in indices:\n",
        "          val_data.append(indices[token])\n",
        "        else:\n",
        "          val_data.append(indices['<unk>'])\n",
        "        if len(val_data) == longest_num_tokens:\n",
        "          break\n",
        "      while len(val_data) < longest_num_tokens:\n",
        "        val_data.append(indices['<pad>'])\n",
        "      val_data.insert(indices['<start>'], 0)\n",
        "      val_data.append(indices['<end>'])\n",
        "      data.append(val_data)\n",
        "      Y.append(label)\n",
        "  else:\n",
        "    for i in range(num_test):\n",
        "      test_data = []\n",
        "      label, tokens = test_labels[i], test_datas[i].split()\n",
        "      for token in tokens:\n",
        "        if token in indices:\n",
        "          test_data.append(indices[token])\n",
        "        else:\n",
        "          test_data.append(indices['<unk>'])\n",
        "        if len(test_data) == longest_num_tokens:\n",
        "          break\n",
        "      while len(test_data) < longest_num_tokens:\n",
        "        test_data.append(indices['<pad>'])\n",
        "      test_data.insert(indices['<start>'], 0)\n",
        "      test_data.append(indices['<end>'])\n",
        "      data.append(test_data)\n",
        "      Y.append(label)\n",
        "  return data, Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lC_nCEVGRQN"
      },
      "outputs": [],
      "source": [
        "# Loading Training Data & Val Data\n",
        "indices = indexing_tokens()\n",
        "train_data, train_labels = get_data(indices, longest_num_tokens)\n",
        "val_data, val_labels = get_data(indices, longest_num_tokens, mode='val')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7M-go4_GRNk",
        "outputId": "0dceb531-0912-4f06-8e1f-3ab65e192358"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training: 1092960\n",
            "Number of validation: 728640\n",
            "Length of corpus: 672492\n"
          ]
        }
      ],
      "source": [
        "print('Number of training:', len(train_data))\n",
        "print('Number of validation:', len(val_data))\n",
        "print('Length of corpus:', len(indices))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftO6Oe0PGRLS"
      },
      "outputs": [],
      "source": [
        "# Create tensors of train & val\n",
        "train_tensor = torch.tensor(train_data)\n",
        "train_labels_tensor = torch.tensor(train_labels)\n",
        "val_tensor = torch.tensor(val_data)\n",
        "val_labels_tensor = torch.tensor(val_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a05SKTeRGRIh",
        "outputId": "831f5edf-de54-4a4f-a4b2-83e30c4a0175"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Tensor: torch.Size([1092960, 252])\n",
            "Val Tensor: torch.Size([728640, 252])\n",
            "Train Label Tensor: torch.Size([1092960])\n",
            "Val Label Tensor: torch.Size([728640])\n"
          ]
        }
      ],
      "source": [
        "print('Train Tensor:', train_tensor.shape)\n",
        "print('Val Tensor:', val_tensor.shape)\n",
        "print('Train Label Tensor:', train_labels_tensor.shape)\n",
        "print('Val Label Tensor:', val_labels_tensor.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8fP11IzGRFx"
      },
      "outputs": [],
      "source": [
        "num_embeddings = len(indices)\n",
        "embedding_dim = 300\n",
        "hidden_dim = 256\n",
        "sequence_len = 252\n",
        "output_dim = 2\n",
        "print_every = 6000\n",
        "batch_size = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dEnRTpIBGRDJ"
      },
      "outputs": [],
      "source": [
        "class MyModel(nn.Module):\n",
        "  def __init__(self, num_embeddings, embedding_dim, hidden_dim, output_dim):\n",
        "    super().__init__()\n",
        "    self.embedding_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "    self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "  def forward(self, x):\n",
        "    # x.shape = N * 252\n",
        "    embedding_data = self.embedding_layer(x)\n",
        "    # x.shape = M * 252 * 100\n",
        "    output, (h_n, c_n) = self.lstm(embedding_data)\n",
        "    out = output[:, -1, :]\n",
        "    return self.fc(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZEIeLVaGRAZ"
      },
      "outputs": [],
      "source": [
        "model = MyModel(num_embeddings, embedding_dim, hidden_dim, output_dim)\n",
        "model = model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OKf3L-GuGQ86"
      },
      "outputs": [],
      "source": [
        "mini_trains = DataLoader(train_tensor, batch_size=batch_size)\n",
        "mini_train_labels = DataLoader(train_labels_tensor, batch_size=batch_size)\n",
        "\n",
        "mini_vals = DataLoader(val_tensor, batch_size=batch_size)\n",
        "mini_val_labels = DataLoader(val_labels_tensor, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smm1EcVINKhc"
      },
      "outputs": [],
      "source": [
        "# Training Procedure\n",
        "def train(num_epoch, model, mini_trains, mini_train_labels, mini_vals, mini_val_labels, device, loss_function, optimizer):\n",
        "  for epoch in range(num_epoch):\n",
        "    for counter, (x, y) in enumerate(zip(mini_trains, mini_train_labels)):\n",
        "      model.train()\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "      scores = model(x)\n",
        "      loss = loss_function(scores, y)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      if counter % print_every == 0:\n",
        "        evaluate_predictor(model, epoch, mini_vals, mini_val_labels, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sb-ZN16fNKes"
      },
      "outputs": [],
      "source": [
        "def evaluate_predictor(model, epoch, mini_vals, mini_val_labels, device):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    total_acc = 0\n",
        "    for x, y in zip(mini_vals, mini_val_labels):\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "      scores = model(x)\n",
        "      predictions = scores.max(1)[1]\n",
        "      acc = predictions.eq(y).sum().item()\n",
        "      total_acc += acc\n",
        "    print(f'Epoch[{epoch+1}] Acc: {total_acc/len(val_data)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZz0XbUBNKcF"
      },
      "outputs": [],
      "source": [
        "# import torch.optim as optim\n",
        "\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPEAwHy0R_Y9",
        "outputId": "86bdf219-4ca3-4bc9-ba58-da88c81fd8b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch[1] Acc: 0.5017937527448397\n",
            "Epoch[1] Acc: 0.4982062472551603\n",
            "Epoch[1] Acc: 0.4982062472551603\n",
            "Epoch[2] Acc: 0.4982062472551603\n",
            "Epoch[2] Acc: 0.6306200592885376\n",
            "Epoch[2] Acc: 0.8600914031620553\n",
            "Epoch[3] Acc: 0.9091650197628458\n",
            "Epoch[3] Acc: 0.9240365612648221\n",
            "Epoch[3] Acc: 0.9294452678963548\n",
            "Epoch[4] Acc: 0.9348622090469917\n",
            "Epoch[4] Acc: 0.9352011967501098\n",
            "Epoch[4] Acc: 0.9397686100131752\n",
            "Epoch[5] Acc: 0.9411959266578832\n",
            "Epoch[5] Acc: 0.9415884387351778\n",
            "Epoch[5] Acc: 0.9436525581906017\n"
          ]
        }
      ],
      "source": [
        "# Start training \n",
        "train(5, model, mini_trains, mini_train_labels, mini_vals, mini_val_labels, device, loss_function, optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-D5dDg_na3Ei"
      },
      "outputs": [],
      "source": [
        "# Loading Testing Data\n",
        "test_data, test_labels = get_data(indices, longest_num_tokens, mode='test')\n",
        "# Create tensors of test\n",
        "test_tensor = torch.tensor(test_data)\n",
        "test_labels_tensor = torch.tensor(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkBkcCRXcQOI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92c1824a-7e83-4acb-b16e-3925613a881f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Tensor: torch.Size([202400, 252])\n",
            "Test Label Tensor: torch.Size([202400])\n"
          ]
        }
      ],
      "source": [
        "print('Test Tensor:', test_tensor.shape)\n",
        "print('Test Label Tensor:', test_labels_tensor.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfZ4bq40cbgX"
      },
      "outputs": [],
      "source": [
        "mini_tests = DataLoader(test_tensor, batch_size=1, shuffle=False)\n",
        "mini_test_labels = DataLoader(test_labels_tensor, batch_size=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvBjCO0Jcl9o"
      },
      "outputs": [],
      "source": [
        "def predict(model, mini_tests, mini_test_labels, device):\n",
        "  model.eval()\n",
        "  start = time.time()\n",
        "  with torch.no_grad():\n",
        "    total_acc = 0\n",
        "    predictions = []\n",
        "    for x, y in zip(mini_tests, mini_test_labels):\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "      scores = model(x)\n",
        "      prediction = scores.max(1)[1]\n",
        "      predictions.append(prediction.item())\n",
        "      acc = prediction.eq(y).sum().item()\n",
        "      total_acc += acc\n",
        "    end = time.time()\n",
        "    elapsed = end - start\n",
        "    print(f'Testing acc: {total_acc/len(test_data)}, tiem_spent: {round(elapsed, 2)} sec')\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0QXRnuJeXKd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fadb016-3c5c-4747-c517-7ab19c2babf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing acc: 0.942895256916996, tiem_spent: 636.72 sec\n"
          ]
        }
      ],
      "source": [
        "predictions = predict(model, mini_tests, mini_test_labels, device)\n",
        "# submission = pd.DataFrame(zip(test_reviews, predictions), columns=['text','label'])\n",
        "# submission.to_csv('submission_lstm.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zOhVezNO44s"
      },
      "outputs": [],
      "source": [
        "# submission.to_csv('submission_lstm.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDzLkL12OFe8"
      },
      "outputs": [],
      "source": [
        "# submission = pd.DataFrame(zip(test_reviews, predictions, test_labels), columns=['text','label', 'ans'])\n",
        "# submission.to_csv('Amazon_Reviews_for_Sentiment_Analysis_lstm.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8luY_yBsR_WU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a01547d-d554-41cf-a41a-70db4b5273b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===============================================\n",
            "Writing predictions to --> Amazon_Reviews_for_Sentiment_Analysis_lstm_0.506.txt\n",
            "===============================================\n"
          ]
        }
      ],
      "source": [
        "def out_file(predictions, test_reviews, test_labels, out_filename):\n",
        "\n",
        "    print('\\n===============================================')\n",
        "    print(f'Writing predictions to --> {out_filename}')\n",
        "    with open(out_filename, 'w') as out:\n",
        "        for prediction, test_review in zip(predictions, test_reviews):\n",
        "          out.write('__label__' + str(prediction+1) + '\\t' + str(test_review) + '\\n')\n",
        "    print('===============================================')\n",
        "\n",
        "out_file(predictions, test_reviews, test_labels, 'Amazon_Reviews_for_Sentiment_Analysis_lstm_0.506.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYGesSbbR_Ts"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUCnzitlR_Rs"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}